{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "Bank XYZ is in the business of giving personal loans, structured as [non-recourse loans](http://www.investopedia.com/terms/n/nonrecoursedebt.asp). The defaults on their loans are much higher than their competitors. Also, the underlying collaterals lose their value way too quicky and has resulted in huge losses for Bank XYZ.\n",
    "\n",
    "Alice was recently appointed as the Senior VP of the Risk Organization. She comes from a strong analytics background and wants to leverage data science to identify customer's risk before approving loan.\n",
    "\n",
    "She's appointed you as a consultant to help her and the team solve this problem.\n",
    "\n",
    "\n",
    "*Note: This case study was inspired by the [bank marketing case study](https://archive.ics.uci.edu/ml/datasets/bank+marketing). The data is a modified version of what is available in that site*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brainstorming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Frame\n",
    "\n",
    "The first step is to convert the business problem into an analytics problem\n",
    "\n",
    "Alice wants to know customer's risk. Let's try to predict the propensity of a customer to default, given the details he/she has entered on the loan application form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Acquire\n",
    "\n",
    "After discussions with the IT team of Bank XYZ, you have obtained some historical data from the bank. It has the following columns\n",
    "\n",
    "**Application Attributes**:\n",
    "- `years`: Number of years the applicant has been employed  \n",
    "- `ownership`: Whether the applicant owns a house or not  \n",
    "- `income`:  Annual income of the applicant  \n",
    "- `age`: Age of the applicant  \n",
    "- `amount` : Amount of Loan requested by the applicant  \n",
    "\n",
    "**Behavioural Attributes**:\n",
    "- `grade`:  Credit grade of the applicant\n",
    "\n",
    "**Outcome Variable**:\n",
    "\n",
    "- `default` : Whether the applicant has defaulted or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defualt Variables\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the training dataset\n",
    "df = pd.read_csv(\"../data/historical_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first few rows of training dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the columns of the train dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data types of the train dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the number of records in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View summary of raw data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the dataset for compeleteness - by checking for missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if df has missing values.\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a large dataset, this is hard to find if there are any missing values or not.\n",
    "# We can chain operators on the output. Let's use sum()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that `years` have missing values. The column is numeric. We have three options for dealing with missing values\n",
    "\n",
    "**Options to treat Missing Values**\n",
    "\n",
    "1. **REMOVE** - NAN rows\n",
    "2. **IMPUTATION** - Replace them with something??\n",
    "     - Mean\n",
    "     - Median\n",
    "     - Fixed Number - Domain Relevant\n",
    "     - High Number (999) - Issue with modelling\n",
    "3. **BINNING** - Categorical variable and \"Missing becomes a number\n",
    "4. **DOMAIN SPECIFIC** - Entry error, pipeline, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace missing values with mean\n",
    "# There's a fillna function\n",
    "df.years = df.years.fillna(np.mean(df.years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, check if training dataframe has missing values or not\n",
    "<your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding unique values of years \n",
    "pd.unique(df.years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to check for quality - by checking for outliers in the data. For this workshop, we will skip doing that. But remember to check for outliers when doing in real-life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build some intuition around the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Single Variable Exploration - Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create histogram for target variable - default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore amount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dual Variable Exploration - Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a crosstab of grade and ownership\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore the impact of age with default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Three Variables Exploration - Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore the relationship between age, income and default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's again revisit the data types in the dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the columns are categorical in nature - grade and ownership.\n",
    "\n",
    "To build models, we need all of the features to be numeric. There exists a number of ways to convert categorical variables to numeric values.\n",
    "\n",
    "We will use one of the popular options: `LabelEncoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's not modify the original dataset. \n",
    "# Let's transform it in another dataset\n",
    "df_encoded = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate label encoder\n",
    "le_grade = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit label encoder\n",
    "le_grade = le_grade.fit(df_encoded[\"grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.grade = le_grade.transform(df_encoded.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Do label encoding on ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Write your code here>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le_ownership = LabelEncoder()\n",
    "#le_ownership = le_ownership.fit(df[\"ownership\"])\n",
    "#df_encoded.ownership = le_ownership.transform(df_encoded.ownership)\n",
    "#df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common approaches:\n",
    "\n",
    "1. Linear models\n",
    "2. Tree-based models\n",
    "3. Bayesian Models\n",
    "4. Artificial Neural Networks\n",
    "\n",
    "Some choices to consider:\n",
    "\n",
    "1. Interpretability\n",
    "2. Run-time\n",
    "3. Model complexity\n",
    "4. Scalability\n",
    "\n",
    "For the purpose of this workshop, we will use tree-based models.\n",
    "\n",
    "We will do the following two:\n",
    "\n",
    "1. Decision Tree\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "Let's first build a model using just three features to build some intuition around decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 -** Create features matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_encoded.loc[:,('age', 'income', 'years')]\n",
    "y = df_encoded.loc[:,'default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2 -** Build decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the decision tree object\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the decision tree model\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 -** Visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file='tree_3.dot', feature_names=X.columns,\n",
    "                                class_names=['no', 'yes'], filled=True, \n",
    "                                rounded=True, special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = pydotplus.graph_from_dot_file('tree_3.dot')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, it makes sense to visualize the decision boundaries, for all the variables - and even make a small animation to see the boundaries in 3-D.\n",
    "\n",
    "This will outside the scope of this workshop. But the related code for this can be found in the speakers' introductory workshop on machine learning [here](https://github.com/amitkaps/applied-machine-learning/blob/master/Module-03b-Model-Trees.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "While we have created the model, we still don't have a *measure* of how good the model is. We need to measure some accuracy metric of the model and have confidence that it will generalize well. We should be confident that when we put the model in production (real-life), the accuracy we get from the model results should mirror the metrics we obtained when we built the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the right accuracy metric for the model is important. \n",
    "\n",
    "[This wiki](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) has a good overview of some of the common metrics.\n",
    "\n",
    "We will use a metric - **Area Under the Curve**\n",
    "\n",
    "#### Area Under the Curve\n",
    "\n",
    "In a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold. A test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100% sensitivity, 100% specificity). Therefore the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test \n",
    "([source](https://www.medcalc.org/manual/roc-curves.php))\n",
    "\n",
    "\n",
    "![](img/roc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Now that we have chosen the error metric, how do we find the generalization error?\n",
    "\n",
    "We do this using cross-validation. ([source]\n",
    "(https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
    "\n",
    "From wiki: \n",
    "> One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.\n",
    "\n",
    "![](img/cv.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `StratifiedKFold`.\n",
    "\n",
    "This ensures that in each fold, the proportion of positive class and negative class remain similar to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate stratified k fold. Let's use 3 fold\n",
    "kf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use an array to store the results of cross-validation\n",
    "kfold_auc_score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process we will follow to get the mean cv-score\n",
    "\n",
    "1. Generate k-fold\n",
    "2. Train the model using k-1 fold\n",
    "3. Predict for the kth fold \n",
    "4. Find the accuracy.\n",
    "5. Append it to the array\n",
    "6. Repeat 2-5 for different validation folds\n",
    "7. Report the mean cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kfold CV\n",
    "\n",
    "for train_index, test_index in kf.split(df_encoded.iloc[:,1:], \n",
    "                                        df_encoded.iloc[:,0]):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "    clf = clf.fit(df_encoded.iloc[train_index,1:], \n",
    "                  df_encoded.iloc[train_index,0])\n",
    "    dt_prediction = clf.predict_proba(df_encoded.iloc[test_index,1:])\n",
    "    auc_score = roc_auc_score(df_encoded.iloc[test_index,0],\n",
    "                            dt_prediction[:,1])\n",
    "    print(auc_score)\n",
    "    kfold_auc_score.append(auc_score)\n",
    "\n",
    "print(\"Mean K Fold CV:\", np.mean(kfold_auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Run 5-fold CV and check if the mean cv-score increases or decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<Your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Decision trees in general have low bias and high variance. We can think about it like this: given a training set, we can keep asking questions until we are able to distinguish between ALL examples in the data set. We could keep asking questions until there is only a single example in each leaf. Since this allows us to correctly classify all elements in the training set, the tree is unbiased. However, there are many possible trees that could distinguish between all elements, which means higher variance.\n",
    "\n",
    "### How do we reduce variance?\n",
    "In order to reduce the variance of a single error tree, we usually place a restriction on the number of questions asked in a tree. This is true  for single decision trees which we have seen in previous notebooks.\n",
    "\n",
    "Along with this other method to do reduce variance is to **ensemble models** of decision trees. The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "### How to ensemble?\n",
    "\n",
    "1. **Averaging**: Build several estimators independently and then average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced. Examples:\n",
    "    - Bagging\n",
    "    - Random Forest\n",
    "    - Extremely Randomized Trees\n",
    " \n",
    "2. **Boosting**: Build base estimators sequentially and then try to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "    - AdaBoost\n",
    "    - Gradient Boosting (e.g. xgboost)\n",
    "    \n",
    "### Random Forest\n",
    "\n",
    "In random forests, each tree in the ensemble is built from a **sample drawn with replacement** (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a **random subset of the features**. \n",
    "\n",
    "As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**\n",
    "\n",
    "The advantage of the `scikit-learn` API is that the syntax remains fairly consistent across all the classifiers.\n",
    "\n",
    "If we change the DecisionTreeClassifier to RandomForestClassifier in the above code, we should be good to go :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate stratified k fold. Let's use 3 fold\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Let's use an array to store the results of cross-validation\n",
    "kfold_auc_score = []\n",
    "\n",
    "# Run kfold CV\n",
    "\n",
    "for train_index, test_index in kf.split(df_encoded.iloc[:,1:], \n",
    "                                        df_encoded.iloc[:,0]):\n",
    "    #The only line that needs change is instantiating the right classifier\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    #End of change\n",
    "    clf = clf.fit(df_encoded.iloc[train_index,1:], \n",
    "                  df_encoded.iloc[train_index,0])\n",
    "    dt_prediction = clf.predict_proba(df_encoded.iloc[test_index,1:])\n",
    "    auc_score = roc_auc_score(df_encoded.iloc[test_index,0],\n",
    "                            dt_prediction[:,1])\n",
    "    print(auc_score)\n",
    "    kfold_auc_score.append(auc_score)\n",
    "\n",
    "print(\"Mean K Fold CV:\", np.mean(kfold_auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Change the number of trees from 10 to 100 and make it 5-fold. And report the cross-validation error (Hint: You should get ~ -.73. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed version of bagging and random forest can be found in the speakers' introductory machine learning workshop material\n",
    "\n",
    "[bagging](https://github.com/amitkaps/applied-machine-learning/blob/master/Module-03d-Model-Bagging.ipynb)  \n",
    "[random forest](https://github.com/amitkaps/applied-machine-learning/blob/master/Module-03e-Model-RandomForest.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "We choose the model and its hyper-parameters that has the best cross-validation score on the chosen error metric.\n",
    "\n",
    "In our case, it is random forest.\n",
    "\n",
    "Now - how do we get the model?\n",
    "\n",
    "We need to run the model with the chosen hyper-parameters on all of the train data. And serialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100)\n",
    "final_model = final_model.fit(df_encoded.iloc[:,1:], \n",
    "                  df_encoded.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to serialize the model and the label encoders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, \"credit_risk_model.pkl\")\n",
    "joblib.dump(le_grade, \"le_grade.pkl\")\n",
    "joblib.dump(le_ownership, \"le_ownership.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
